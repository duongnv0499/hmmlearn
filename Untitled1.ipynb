{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "    return kmeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load nguoi dataset\n",
      "Load test_nguoi dataset\n",
      "Load cua dataset\n",
      "Load test_cua dataset\n",
      "Load va dataset\n",
      "Load test_va dataset\n",
      "Load khong dataset\n",
      "Load test_khong dataset\n",
      "Load benh_nhan dataset\n",
      "Load test_benh_nhan dataset\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"nguoi\", \"test_nguoi\", \"cua\", \"test_cua\", \"va\", \"test_va\", \"khong\", \"test_khong\", \"benh_nhan\", \"test_benh_nhan\"]\n",
    "trainset = {}\n",
    "testset= {}\n",
    "\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    if (cname[:4] =='test') : \n",
    "        testset[cname] = get_class_data(os.path.join(\"hmm_data\", cname))\n",
    "    else:\n",
    "        trainset[cname] = get_class_data(os.path.join(\"hmm_data\", cname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vectors (9974, 36)\n",
      "test_vectors (4362, 36)\n",
      "centers (10, 36)\n",
      "centers (10, 36)\n",
      "centers (10, 36)\n"
     ]
    }
   ],
   "source": [
    "train_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in trainset.items()], axis=0)\n",
    "test_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in testset.items()], axis=0)\n",
    "print(\"train_vectors\", train_vectors.shape)\n",
    "print(\"test_vectors\", test_vectors.shape)\n",
    "# Run K-Means algorithm to get clusters\n",
    "kmeans = clustering(train_vectors)\n",
    "kmeans = clustering(test_vectors)\n",
    "print(\"centers\", kmeans.cluster_centers_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_config(cname):\n",
    "    if cname == 'va' :\n",
    "        startprob=np.array([0.7,0.2,0.1,0.0,0.0,0.0]),\n",
    "        transmat=np.array([\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.1,0.5,0.1,0.1,0.1,],\n",
    "            [0.1,0.1,0.1,0.5,0.1,0.1,],\n",
    "            [0.1,0.1,0.1,0.1,0.5,0.1,],\n",
    "            [0.1,0.1,0.1,0.5,0.1,0.1,],\n",
    "            [0.1,0.1,0.1,0.1,0.5,0.1,],\n",
    "        ]),\n",
    "        return startprob, transmat\n",
    "    if cname == 'cua':\n",
    "        startprob=np.array([0.7,0.2,0.1,0.0,0.0,0.0]),\n",
    "        transmat=np.array([\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,],\n",
    "            [0.1,0.1,0.5,0.1,0.1,0.1,],\n",
    "            [0.1,0.1,0.1,0.5,0.1,0.1,],\n",
    "            [0.1,0.1,0.1,0.1,0.5,0.1,],\n",
    "            [0.1,0.1,0.1,0.1,0.1,0.5,],\n",
    "            [0.1,0.1,0.1,0.1,0.1,0.5,],\n",
    "        ]),\n",
    "        return startprob, transmat\n",
    "    if cname == 'nguoi':\n",
    "        startprob=np.array([0.7,0.2,0.1,0.0,0.0,0.0]),\n",
    "        transmat=np.array([\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,],\n",
    "            [0.1,0.1,0.5,0.1,0.1,0.1,],\n",
    "            [0.1,0.1,0.1,0.5,0.1,0.1,],\n",
    "            [0.1,0.1,0.1,0.1,0.5,0.1,],\n",
    "            [0.1,0.1,0.1,0.1,0.1,0.5,],\n",
    "            [0.1,0.1,0.1,0.1,0.1,0.5,],\n",
    "        ]),\n",
    "        return startprob, transmat\n",
    "    if cname == 'khong':\n",
    "        startprob=np.array([0.7,0.2,0.1,0.0,0.0,0.0]),\n",
    "        transmat=np.array([\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,],\n",
    "            [0.1,0.1,0.5,0.1,0.1,0.1,],\n",
    "            [0.1,0.1,0.1,0.5,0.1,0.1,],\n",
    "            [0.1,0.1,0.1,0.1,0.5,0.1,],\n",
    "            [0.1,0.1,0.1,0.1,0.1,0.5,],\n",
    "            [0.1,0.1,0.1,0.1,0.1,0.5,],\n",
    "        ]),\n",
    "        return startprob, transmat\n",
    "    if cname == 'benh_nhan':\n",
    "        startprob=np.array([0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1]),\n",
    "        transmat=np.array([\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "            [0.1,0.5,0.1,0.1,0.1,0.1,0.1,0.5,0.1,0.1,0.1,0.1],\n",
    "        ]),\n",
    "        return startprob, transmat\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class nguoi\n",
      "(1708, 1) [17, 39, 29, 24, 30, 17, 30, 20, 13, 27, 20, 19, 26, 20, 23, 30, 21, 17, 19, 40, 20, 49, 41, 53, 28, 27, 28, 28, 14, 20, 42, 19, 19, 19, 21, 21, 22, 30, 23, 29, 23, 27, 20, 21, 26, 23, 28, 25, 18, 22, 15, 22, 30, 19, 21, 24, 25, 26, 16, 16, 17, 23, 20, 20, 27, 20, 24, 32, 18, 26] 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -3867.2574             +nan\n",
      "         2       -3523.1029        +344.1545\n",
      "         3       -3499.2446         +23.8583\n",
      "         4       -3456.0332         +43.2114\n",
      "         5       -3383.7822         +72.2510\n",
      "         6       -3284.0121         +99.7702\n",
      "         7       -3126.3673        +157.6448\n",
      "         8       -2908.8060        +217.5613\n",
      "         9       -2709.2677        +199.5384\n",
      "        10       -2574.1413        +135.1263\n",
      "        11       -2512.6351         +61.5062\n",
      "        12       -2478.2487         +34.3864\n",
      "        13       -2446.8676         +31.3812\n",
      "        14       -2413.7185         +33.1490\n",
      "        15       -2381.5067         +32.2118\n",
      "        16       -2346.8571         +34.6496\n",
      "        17       -2312.4229         +34.4342\n",
      "        18       -2286.6018         +25.8210\n",
      "        19       -2270.3052         +16.2966\n",
      "        20       -2260.3175          +9.9877\n",
      "        21       -2254.4911          +5.8265\n",
      "        22       -2251.2880          +3.2031\n",
      "        23       -2249.4782          +1.8097\n",
      "        24       -2248.3222          +1.1560\n",
      "        25       -2247.4972          +0.8250\n",
      "        26       -2246.8918          +0.6054\n",
      "        27       -2246.4724          +0.4194\n",
      "        28       -2246.2023          +0.2701\n",
      "        29       -2246.0322          +0.1702\n",
      "        30       -2245.9216          +0.1105\n",
      "        31       -2245.8462          +0.0755\n",
      "        32       -2245.7921          +0.0541\n",
      "        33       -2245.7518          +0.0403\n",
      "        34       -2245.7208          +0.0311\n",
      "        35       -2245.6961          +0.0247\n",
      "        36       -2245.6759          +0.0202\n",
      "        37       -2245.6588          +0.0170\n",
      "        38       -2245.6440          +0.0148\n",
      "        39       -2245.6308          +0.0132\n",
      "        40       -2245.6186          +0.0122\n",
      "        41       -2245.6070          +0.0116\n",
      "        42       -2245.5958          +0.0112\n",
      "        43       -2245.5846          +0.0112\n",
      "        44       -2245.5732          +0.0114\n",
      "        45       -2245.5615          +0.0117\n",
      "        46       -2245.5493          +0.0122\n",
      "        47       -2245.5364          +0.0129\n",
      "        48       -2245.5227          +0.0137\n",
      "        49       -2245.5081          +0.0146\n",
      "        50       -2245.4926          +0.0155\n",
      "        51       -2245.4760          +0.0165\n",
      "        52       -2245.4585          +0.0176\n",
      "        53       -2245.4399          +0.0186\n",
      "        54       -2245.4204          +0.0195\n",
      "        55       -2245.4000          +0.0204\n",
      "        56       -2245.3788          +0.0212\n",
      "        57       -2245.3569          +0.0218\n",
      "        58       -2245.3346          +0.0223\n",
      "        59       -2245.3120          +0.0226\n",
      "        60       -2245.2893          +0.0227\n",
      "        61       -2245.2666          +0.0226\n",
      "        62       -2245.2443          +0.0224\n",
      "        63       -2245.2223          +0.0219\n",
      "        64       -2245.2010          +0.0213\n",
      "        65       -2245.1804          +0.0206\n",
      "        66       -2245.1606          +0.0198\n",
      "        67       -2245.1418          +0.0189\n",
      "        68       -2245.1239          +0.0179\n",
      "        69       -2245.1071          +0.0169\n",
      "        70       -2245.0912          +0.0158\n",
      "        71       -2245.0764          +0.0148\n",
      "        72       -2245.0627          +0.0138\n",
      "        73       -2245.0499          +0.0128\n",
      "        74       -2245.0381          +0.0118\n",
      "        75       -2245.0273          +0.0109\n",
      "        76       -2245.0173          +0.0100\n",
      "         1       -4825.8701             +nan\n",
      "         2       -4437.4080        +388.4621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class cua\n",
      "(2139, 1) [25, 38, 34, 22, 24, 26, 22, 24, 49, 28, 24, 28, 39, 26, 32, 30, 24, 33, 40, 36, 51, 29, 28, 33, 26, 28, 24, 31, 37, 22, 28, 27, 31, 37, 39, 26, 26, 28, 40, 29, 32, 33, 21, 26, 24, 47, 22, 35, 26, 38, 24, 26, 27, 30, 24, 30, 40, 34, 29, 26, 42, 21, 36, 25, 24, 43, 40, 26, 42, 22] 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         3       -4415.4370         +21.9710\n",
      "         4       -4380.7052         +34.7318\n",
      "         5       -4323.6816         +57.0236\n",
      "         6       -4237.6436         +86.0380\n",
      "         7       -4121.7229        +115.9208\n",
      "         8       -3941.6541        +180.0687\n",
      "         9       -3681.4704        +260.1837\n",
      "        10       -3483.9961        +197.4743\n",
      "        11       -3386.2891         +97.7070\n",
      "        12       -3296.1077         +90.1814\n",
      "        13       -3211.6910         +84.4167\n",
      "        14       -3157.6230         +54.0680\n",
      "        15       -3120.3323         +37.2907\n",
      "        16       -3088.8503         +31.4820\n",
      "        17       -3064.0767         +24.7736\n",
      "        18       -3046.7539         +17.3228\n",
      "        19       -3034.7161         +12.0378\n",
      "        20       -3026.2679          +8.4483\n",
      "        21       -3020.2370          +6.0309\n",
      "        22       -3015.5483          +4.6887\n",
      "        23       -3011.2376          +4.3107\n",
      "        24       -3006.5221          +4.7156\n",
      "        25       -2997.1075          +9.4146\n",
      "        26       -2983.4924         +13.6151\n",
      "        27       -2977.5072          +5.9852\n",
      "        28       -2975.0610          +2.4462\n",
      "        29       -2973.4665          +1.5944\n",
      "        30       -2972.1857          +1.2809\n",
      "        31       -2971.1428          +1.0429\n",
      "        32       -2970.3209          +0.8219\n",
      "        33       -2969.6763          +0.6446\n",
      "        34       -2969.1604          +0.5159\n",
      "        35       -2968.7360          +0.4244\n",
      "        36       -2968.3758          +0.3601\n",
      "        37       -2968.0600          +0.3158\n",
      "        38       -2967.7737          +0.2863\n",
      "        39       -2967.5055          +0.2682\n",
      "        40       -2967.2465          +0.2591\n",
      "        41       -2966.9890          +0.2575\n",
      "        42       -2966.7270          +0.2621\n",
      "        43       -2966.4555          +0.2714\n",
      "        44       -2966.1719          +0.2836\n",
      "        45       -2965.8758          +0.2961\n",
      "        46       -2965.5699          +0.3058\n",
      "        47       -2965.2603          +0.3096\n",
      "        48       -2964.9548          +0.3055\n",
      "        49       -2964.6615          +0.2933\n",
      "        50       -2964.3864          +0.2752\n",
      "        51       -2964.1320          +0.2544\n",
      "        52       -2963.8985          +0.2336\n",
      "        53       -2963.6847          +0.2137\n",
      "        54       -2963.4897          +0.1950\n",
      "        55       -2963.3120          +0.1777\n",
      "        56       -2963.1492          +0.1628\n",
      "        57       -2962.9981          +0.1511\n",
      "        58       -2962.8555          +0.1426\n",
      "        59       -2962.7188          +0.1367\n",
      "        60       -2962.5867          +0.1321\n",
      "        61       -2962.4588          +0.1279\n",
      "        62       -2962.3358          +0.1230\n",
      "        63       -2962.2190          +0.1167\n",
      "        64       -2962.1102          +0.1088\n",
      "        65       -2962.0111          +0.0991\n",
      "        66       -2961.9229          +0.0882\n",
      "        67       -2961.8464          +0.0765\n",
      "        68       -2961.7815          +0.0649\n",
      "        69       -2961.7275          +0.0540\n",
      "        70       -2961.6835          +0.0441\n",
      "        71       -2961.6479          +0.0355\n",
      "        72       -2961.6196          +0.0284\n",
      "        73       -2961.5970          +0.0225\n",
      "        74       -2961.5791          +0.0179\n",
      "        75       -2961.5648          +0.0143\n",
      "        76       -2961.5533          +0.0115\n",
      "        77       -2961.5440          +0.0093\n",
      "         1       -2962.9149             +nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class va\n",
      "(1292, 1) [18, 17, 20, 18, 24, 20, 19, 17, 19, 16, 18, 17, 18, 24, 19, 18, 17, 22, 13, 23, 28, 13, 20, 22, 16, 17, 23, 13, 15, 23, 17, 23, 17, 19, 14, 13, 21, 21, 17, 17, 13, 14, 17, 17, 18, 19, 19, 16, 16, 24, 21, 18, 12, 22, 20, 18, 21, 29, 29, 19, 24, 19, 17, 18, 17, 22, 13, 16, 18] 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         2       -2752.1838        +210.7310\n",
      "         3       -2733.0805         +19.1033\n",
      "         4       -2704.9170         +28.1636\n",
      "         5       -2659.8132         +45.1038\n",
      "         6       -2596.8362         +62.9770\n",
      "         7       -2531.1381         +65.6980\n",
      "         8       -2470.7096         +60.4285\n",
      "         9       -2405.4413         +65.2683\n",
      "        10       -2333.6369         +71.8044\n",
      "        11       -2265.8424         +67.7945\n",
      "        12       -2213.8370         +52.0054\n",
      "        13       -2175.7162         +38.1207\n",
      "        14       -2136.2301         +39.4861\n",
      "        15       -2096.9313         +39.2988\n",
      "        16       -2062.6370         +34.2944\n",
      "        17       -2037.4981         +25.1389\n",
      "        18       -2024.1965         +13.3016\n",
      "        19       -2016.4988          +7.6977\n",
      "        20       -2009.6915          +6.8073\n",
      "        21       -2001.3403          +8.3512\n",
      "        22       -1986.9577         +14.3825\n",
      "        23       -1945.0562         +41.9015\n",
      "        24       -1845.3126         +99.7436\n",
      "        25       -1811.4906         +33.8220\n",
      "        26       -1805.3075          +6.1830\n",
      "        27       -1801.6871          +3.6204\n",
      "        28       -1799.4462          +2.2409\n",
      "        29       -1797.9545          +1.4918\n",
      "        30       -1796.8512          +1.1033\n",
      "        31       -1795.9547          +0.8965\n",
      "        32       -1795.1908          +0.7639\n",
      "        33       -1794.5389          +0.6518\n",
      "        34       -1793.9923          +0.5466\n",
      "        35       -1793.5374          +0.4549\n",
      "        36       -1793.1518          +0.3856\n",
      "        37       -1792.8098          +0.3420\n",
      "        38       -1792.4867          +0.3231\n",
      "        39       -1792.1587          +0.3280\n",
      "        40       -1791.8010          +0.3577\n",
      "        41       -1791.3825          +0.4185\n",
      "        42       -1790.8573          +0.5253\n",
      "        43       -1790.1497          +0.7076\n",
      "        44       -1789.1328          +1.0168\n",
      "        45       -1787.6085          +1.5243\n",
      "        46       -1785.3081          +2.3004\n",
      "        47       -1781.8654          +3.4427\n",
      "        48       -1777.0535          +4.8118\n",
      "        49       -1772.0431          +5.0104\n",
      "        50       -1768.2022          +3.8408\n",
      "        51       -1765.6832          +2.5190\n",
      "        52       -1764.2021          +1.4811\n",
      "        53       -1763.4046          +0.7975\n",
      "        54       -1762.9835          +0.4211\n",
      "        55       -1762.7186          +0.2649\n",
      "        56       -1762.2746          +0.4440\n",
      "        57       -1760.8310          +1.4436\n",
      "        58       -1759.1686          +1.6624\n",
      "        59       -1758.3847          +0.7839\n",
      "        60       -1758.0679          +0.3168\n",
      "        61       -1757.9138          +0.1541\n",
      "        62       -1757.8179          +0.0959\n",
      "        63       -1757.7487          +0.0692\n",
      "        64       -1757.6949          +0.0537\n",
      "        65       -1757.6516          +0.0433\n",
      "        66       -1757.6159          +0.0357\n",
      "        67       -1757.5860          +0.0299\n",
      "        68       -1757.5604          +0.0255\n",
      "        69       -1757.5383          +0.0221\n",
      "        70       -1757.5187          +0.0196\n",
      "        71       -1757.5007          +0.0180\n",
      "        72       -1757.4836          +0.0171\n",
      "        73       -1757.4663          +0.0172\n",
      "        74       -1757.4480          +0.0183\n",
      "        75       -1757.4276          +0.0205\n",
      "        76       -1757.4039          +0.0236\n",
      "        77       -1757.3766          +0.0273\n",
      "        78       -1757.3462          +0.0304\n",
      "        79       -1757.3143          +0.0319\n",
      "        80       -1757.2836          +0.0307\n",
      "        81       -1757.2567          +0.0269\n",
      "        82       -1757.2351          +0.0216\n",
      "        83       -1757.2188          +0.0163\n",
      "        84       -1757.2070          +0.0118\n",
      "        85       -1757.1986          +0.0085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class khong\n",
      "(2083, 1) [27, 36, 30, 20, 24, 23, 25, 32, 26, 22, 37, 42, 32, 28, 20, 46, 49, 31, 42, 17, 24, 47, 26, 24, 43, 24, 37, 27, 28, 27, 43, 33, 24, 40, 21, 31, 55, 31, 28, 27, 26, 23, 30, 21, 29, 37, 25, 28, 24, 27, 29, 27, 33, 32, 32, 26, 21, 49, 23, 20, 33, 25, 28, 26, 19, 25, 23, 32, 26, 35] 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -4832.4107             +nan\n",
      "         2       -4552.6577        +279.7530\n",
      "         3       -4494.3908         +58.2669\n",
      "         4       -4387.4323        +106.9585\n",
      "         5       -4216.1477        +171.2846\n",
      "         6       -3982.6045        +233.5432\n",
      "         7       -3742.7168        +239.8878\n",
      "         8       -3503.7576        +238.9591\n",
      "         9       -3197.9338        +305.8238\n",
      "        10       -2976.6578        +221.2760\n",
      "        11       -2914.4237         +62.2342\n",
      "        12       -2891.6348         +22.7889\n",
      "        13       -2863.4375         +28.1973\n",
      "        14       -2828.6081         +34.8295\n",
      "        15       -2801.5302         +27.0778\n",
      "        16       -2784.8335         +16.6967\n",
      "        17       -2774.8636          +9.9699\n",
      "        18       -2768.8519          +6.0117\n",
      "        19       -2764.7332          +4.1187\n",
      "        20       -2761.6731          +3.0601\n",
      "        21       -2759.4401          +2.2330\n",
      "        22       -2757.9298          +1.5104\n",
      "        23       -2756.9717          +0.9581\n",
      "        24       -2756.3754          +0.5963\n",
      "        25       -2756.0031          +0.3723\n",
      "        26       -2755.7687          +0.2344\n",
      "        27       -2755.6191          +0.1496\n",
      "        28       -2755.5214          +0.0977\n",
      "        29       -2755.4554          +0.0660\n",
      "        30       -2755.4091          +0.0464\n",
      "        31       -2755.3750          +0.0341\n",
      "        32       -2755.3486          +0.0263\n",
      "        33       -2755.3274          +0.0213\n",
      "        34       -2755.3094          +0.0179\n",
      "        35       -2755.2937          +0.0157\n",
      "        36       -2755.2795          +0.0142\n",
      "        37       -2755.2662          +0.0133\n",
      "        38       -2755.2536          +0.0127\n",
      "        39       -2755.2412          +0.0123\n",
      "        40       -2755.2290          +0.0122\n",
      "        41       -2755.2167          +0.0123\n",
      "        42       -2755.2041          +0.0125\n",
      "        43       -2755.1913          +0.0128\n",
      "        44       -2755.1781          +0.0132\n",
      "        45       -2755.1645          +0.0136\n",
      "        46       -2755.1505          +0.0140\n",
      "        47       -2755.1361          +0.0144\n",
      "        48       -2755.1213          +0.0147\n",
      "        49       -2755.1063          +0.0150\n",
      "        50       -2755.0911          +0.0152\n",
      "        51       -2755.0758          +0.0153\n",
      "        52       -2755.0605          +0.0153\n",
      "        53       -2755.0452          +0.0153\n",
      "        54       -2755.0300          +0.0152\n",
      "        55       -2755.0149          +0.0151\n",
      "        56       -2755.0000          +0.0149\n",
      "        57       -2754.9853          +0.0147\n",
      "        58       -2754.9707          +0.0146\n",
      "        59       -2754.9563          +0.0144\n",
      "        60       -2754.9421          +0.0142\n",
      "        61       -2754.9280          +0.0141\n",
      "        62       -2754.9142          +0.0139\n",
      "        63       -2754.9006          +0.0136\n",
      "        64       -2754.8873          +0.0133\n",
      "        65       -2754.8744          +0.0129\n",
      "        66       -2754.8621          +0.0123\n",
      "        67       -2754.8506          +0.0116\n",
      "        68       -2754.8398          +0.0107\n",
      "        69       -2754.8301          +0.0098\n",
      "         1       -6319.3982             +nan\n",
      "         2       -5452.0934        +867.3048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class benh_nhan\n",
      "(2752, 1) [29, 41, 52, 55, 44, 44, 45, 32, 45, 34, 38, 45, 28, 30, 41, 43, 32, 32, 31, 30, 34, 26, 45, 30, 45, 44, 30, 33, 40, 35, 30, 42, 29, 43, 42, 43, 31, 41, 43, 41, 47, 54, 35, 39, 52, 51, 39, 32, 46, 46, 46, 48, 40, 38, 46, 30, 33, 63, 36, 41, 34, 36, 44, 33, 43, 41, 35, 37, 34, 35] 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         3       -5410.4786         +41.6148\n",
      "         4       -5339.1477         +71.3309\n",
      "         5       -5222.2061        +116.9416\n",
      "         6       -5066.8970        +155.3091\n",
      "         7       -4910.3786        +156.5184\n",
      "         8       -4753.5073        +156.8712\n",
      "         9       -4560.5928        +192.9145\n",
      "        10       -4349.3121        +211.2807\n",
      "        11       -4165.9063        +183.4058\n",
      "        12       -4044.3188        +121.5875\n",
      "        13       -3953.3988         +90.9200\n",
      "        14       -3880.6666         +72.7323\n",
      "        15       -3831.7493         +48.9173\n",
      "        16       -3802.6158         +29.1335\n",
      "        17       -3785.4065         +17.2093\n",
      "        18       -3773.7240         +11.6824\n",
      "        19       -3764.2809          +9.4431\n",
      "        20       -3755.5252          +8.7557\n",
      "        21       -3747.0250          +8.5002\n",
      "        22       -3738.9222          +8.1029\n",
      "        23       -3731.5812          +7.3410\n",
      "        24       -3725.5926          +5.9886\n",
      "        25       -3721.3657          +4.2269\n",
      "        26       -3718.6529          +2.7128\n",
      "        27       -3716.9017          +1.7512\n",
      "        28       -3715.7016          +1.2001\n",
      "        29       -3714.8359          +0.8657\n",
      "        30       -3714.1956          +0.6403\n",
      "        31       -3713.7179          +0.4777\n",
      "        32       -3713.3597          +0.3582\n",
      "        33       -3713.0883          +0.2714\n",
      "        34       -3712.8787          +0.2096\n",
      "        35       -3712.7125          +0.1662\n",
      "        36       -3712.5768          +0.1357\n",
      "        37       -3712.4627          +0.1141\n",
      "        38       -3712.3640          +0.0986\n",
      "        39       -3712.2767          +0.0873\n",
      "        40       -3712.1977          +0.0790\n",
      "        41       -3712.1249          +0.0728\n",
      "        42       -3712.0568          +0.0681\n",
      "        43       -3711.9922          +0.0646\n",
      "        44       -3711.9302          +0.0620\n",
      "        45       -3711.8701          +0.0601\n",
      "        46       -3711.8114          +0.0587\n",
      "        47       -3711.7537          +0.0577\n",
      "        48       -3711.6967          +0.0570\n",
      "        49       -3711.6402          +0.0565\n",
      "        50       -3711.5841          +0.0561\n",
      "        51       -3711.5282          +0.0559\n",
      "        52       -3711.4723          +0.0559\n",
      "        53       -3711.4162          +0.0561\n",
      "        54       -3711.3597          +0.0565\n",
      "        55       -3711.3022          +0.0575\n",
      "        56       -3711.2431          +0.0591\n",
      "        57       -3711.1811          +0.0619\n",
      "        58       -3711.1146          +0.0665\n",
      "        59       -3711.0406          +0.0740\n",
      "        60       -3710.9545          +0.0861\n",
      "        61       -3710.8482          +0.1063\n",
      "        62       -3710.7076          +0.1405\n",
      "        63       -3710.5067          +0.2009\n",
      "        64       -3710.1947          +0.3120\n",
      "        65       -3709.6705          +0.5242\n",
      "        66       -3708.7422          +0.9283\n",
      "        67       -3707.1120          +1.6302\n",
      "        68       -3704.4735          +2.6384\n",
      "        69       -3700.6493          +3.8243\n",
      "        70       -3695.7348          +4.9145\n",
      "        71       -3690.3679          +5.3669\n",
      "        72       -3685.7015          +4.6664\n",
      "        73       -3682.5262          +3.1752\n",
      "        74       -3680.7067          +1.8195\n",
      "        75       -3679.7467          +0.9600\n",
      "        76       -3679.2525          +0.4942\n",
      "        77       -3678.9934          +0.2591\n",
      "        78       -3678.8509          +0.1425\n",
      "        79       -3678.7671          +0.0838\n",
      "        80       -3678.7132          +0.0539\n",
      "        81       -3678.6740          +0.0392\n",
      "        82       -3678.6399          +0.0341\n",
      "        83       -3678.6034          +0.0365\n",
      "        84       -3678.5581          +0.0452\n",
      "        85       -3678.5012          +0.0569\n",
      "        86       -3678.4375          +0.0637\n",
      "        87       -3678.3795          +0.0581\n",
      "        88       -3678.3374          +0.0420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        89       -3678.3123          +0.0251\n",
      "        90       -3678.2989          +0.0134\n",
      "        91       -3678.2919          +0.0070\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for cname in class_names:\n",
    "    if cname[:4] != \"test\":\n",
    "        class_vectors = trainset[cname]\n",
    "        # convert all vectors to the cluster index\n",
    "        # dataset['one'] = [O^1, ... O^R]\n",
    "        # O^r = (c1, c2, ... ct, ... cT)\n",
    "        # O^r size T x 1\n",
    "        trainset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in trainset[cname]])\n",
    "        \n",
    "        startprob_, transmat_ = get_start_config(cname)\n",
    "        \n",
    "        hmm = hmmlearn.hmm.MultinomialHMM(n_components=6, random_state=0, n_iter=1000, verbose=True)\n",
    "        hmm.startprob_ = startprob_\n",
    "        hmm.transmat_ = transmat_\n",
    "#         if cname[:4] != 'test':\n",
    "        X = np.concatenate(trainset[cname])\n",
    "        lengths = list([len(x) for x in trainset[cname]])\n",
    "        print(\"training class\", cname)\n",
    "        print(X.shape, lengths, len(lengths))\n",
    "        hmm.fit(X, lengths=lengths)\n",
    "        models[cname] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-1ec12ad25fa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-432d75f8458b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrue_cname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrue_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mO\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_cname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcname\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrue_cname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_prid_correct\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtest_prid_correct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_cname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_cname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' predict '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-227-432d75f8458b>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrue_cname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrue_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mO\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_cname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcname\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrue_cname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_prid_correct\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtest_prid_correct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_cname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_cname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' predict '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mlogprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_from_X_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mframelogprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mlogprobij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fwdlattice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframelogprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mlogprob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogprobij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/hmmlearn/hmm.py\u001b[0m in \u001b[0;36m_compute_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_mask_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissionprob_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_generate_sample_from_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Testing\")\n",
    "true_names=[\"cua\", \"nguoi\", \"va\", \"benh_nhan\", \"khong\"]\n",
    "true_test=['test_cua', 'test_nguoi', 'test_va', 'test_benh_nhan', 'test_khong']\n",
    "prid_correct={'cua' : 0, 'nguoi':0, 'va':0, 'benh_nhan':0, 'khong':0}\n",
    "test_prid_correct = {'test_cua':0, 'test_nguoi':0, 'test_va':0, 'test_benh_nhan':0, 'test_khong':0}\n",
    "#true_label=[1, 2, 3, 4]\n",
    "for true_cname in true_test:\n",
    "    for O in testset[true_cname]:\n",
    "        score = {cname : model.score(O) for true_cname, model in models.items()}\n",
    "        if (test_prid_correct == max(score, key=score.get)) : test_prid_correct[true_cname]+=1\n",
    "        print(true_cname, ' predict ', max(score, key=score.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
